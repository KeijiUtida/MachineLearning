# -*- coding: utf-8 -*-
"""Pratica1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d8yYy03ceXFMBnRBJZUMZ-Ejz13Ed-8U
"""

from os import listdir
from google.colab import drive
drive.mount('/content/drive')

"""Importando dados"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import glob                                                                                     
import statistics

train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Trem/train.csv')
test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Trem/test.csv')
#pd.read_csv(f , index_col=None, header=None, names=['Time','Sv','Ac1','Ac2','Ac3'])

train

"""Funçao para construir o dataset"""

def CreateDataset(listOfObj, isTrain):
    #separaçao por titulo no Nome
    AuxValues1 = list()
    for names in listOfObj['Name']:
          if "Mr." in names:
              AuxValues1.append(1)
          if "Miss." in names:
              AuxValues1.append(2)
          if "Ms." in names:
              AuxValues1.append(2)
          if "Capt." in names:
              AuxValues1.append(3)
          if "Master." in names:
              AuxValues1.append(4)
          if "Mrs." in names:
              AuxValues1.append(5)
          if "Dr." in names:
              AuxValues1.append(6)
          if "Rev." in names:
              AuxValues1.append(7)
          if "Mme." in names:
              AuxValues1.append(8)
          if "Mlle." in names:
              AuxValues1.append(2)
          if "Don." in names:
              AuxValues1.append(9)
          if "Major." in names:
              AuxValues1.append(3)
          if "Sir." in names:
              AuxValues1.append(10)
          if "Col." in names:
              AuxValues1.append(3)
          if "Countess." in names:
              AuxValues1.append(10)
          if "Jonkheer." in names:
              AuxValues1.append(10)
          if "Lady." in names:
              AuxValues1.append(5)
          if "Dona." in names:
              AuxValues1.append(5)
        
        
    
          
    #Quantidade de pessoas na cabine
    AuxValues2=listOfObj['SibSp']+1  
    
    #Idade
    #Removendo Nan
    listOfObj['Age'] = listOfObj['Age'].replace(np.nan, 999)
    #criando categorias
    AuxValues3 = list()
    for Age in listOfObj['Age']:
        if Age >= 0 and Age < 7:
            AuxValues3.append(1)
        if Age >= 7 and Age <15:
            AuxValues3.append(2)
        if Age >= 15 and Age <25:
            AuxValues3.append(3)
        if Age >= 25 and Age<35:
            AuxValues3.append(4)
        if Age >= 35 and Age<45:
            AuxValues3.append(5)
        if Age >= 45 and Age <60:
            AuxValues3.append(6)
        if Age >=60:
            AuxValues3.append(7)
        if Age == 999:
            AuxValues3.append(0)
    
        
    #sex
    AuxValues4 = list()
    listOfObj.dropna(subset= ['Sex'],axis=0)
    for sex in listOfObj['Sex']:
        if "female" in sex:
            AuxValues4.append(1)
        else:
            AuxValues4.append(0)
            
    #fare
    listOfObj['Fare'] = listOfObj['Fare'].replace(np.nan, 0)
    AuxValues5 = list()
    for fare in listOfObj['Fare']:
        if fare < 20:
            AuxValues5.append(0)
        if fare >= 20 and fare <100:
            AuxValues5.append(1)
        if fare >= 100 and fare <200:
            AuxValues5.append(2)
        if fare >= 200:
            AuxValues5.append(3)
    
    #Cabin
    listOfObj['Cabin'] = listOfObj['Cabin'].replace(np.nan, 'X')
    AuxValues6 = list()
    for cabin in listOfObj['Cabin']:
        cabin = cabin.split(" ")[0]
        if "A"  in cabin:
            AuxValues6.append(1)
        if "B" in cabin:
            AuxValues6.append(2)       
        if "C" in cabin:
            AuxValues6.append(3)       
        if "D" in cabin:
            AuxValues6.append(4)       
        if "E" in cabin:
            AuxValues6.append(5)             
        if "F" in cabin:
            AuxValues6.append(6)          
        if "G" in cabin:
            AuxValues6.append(7)  
        if "T" in cabin:
            AuxValues6.append(8)  
        if "X" in cabin:
            AuxValues6.append(0)            
            
    
    listOfObj['Embarked'] = listOfObj['Embarked'].replace(np.nan, 0)
    listOfObj['Embarked'] = listOfObj['Embarked'].replace('C', 1)
    listOfObj['Embarked'] = listOfObj['Embarked'].replace('S', 2)
    listOfObj['Embarked'] = listOfObj['Embarked'].replace('Q', 3)
    AuxValues1 = np.array(AuxValues1) 
    AuxValues2 = np.array(AuxValues2) 
    AuxValues3 = np.array(AuxValues3)
    AuxValues4 = np.array(AuxValues4)
    AuxValues5 = np.array(AuxValues5)
    AuxValues6 = np.array(AuxValues6)
    
    a = np.c_[listOfObj,AuxValues1,AuxValues2,AuxValues3,AuxValues4,AuxValues5,AuxValues6]

    a = np.delete(a, [2+isTrain, 3+isTrain, 4+isTrain, 7+isTrain, 8+isTrain, 9+isTrain], 1)
    return a

"""Construindo dataset"""

train = CreateDataset(train, 1)
test = CreateDataset(test, 0)

"""Treinamento => Dataset de treino

"""

from sklearn.model_selection import train_test_split

X = train[:, [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]
y = train[:, 1]
Z_test = test[:, [1, 2, 3, 4, 5, 6, 7, 8, 9,10]]

Z_test=Z_test.astype('int')
X=X.astype('int')
y=y.astype('int')

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)

"""Padronizando data"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()
X_train_std = sc.fit_transform(X_train)
X_test_std = sc.transform(X_test)
X_ans_test_std = sc.transform(Z_test)

"""Plot => variancia emplicada"""

from sklearn.decomposition import PCA

pca = PCA()
X_train_pca = pca.fit_transform(X_train_std)
pca.explained_variance_ratio_

import matplotlib.pyplot as plt

plt.bar(range(1, 11), pca.explained_variance_ratio_, alpha=0.5, align='center')
plt.step(range(1, 11), np.cumsum(pca.explained_variance_ratio_), where='mid')
plt.ylabel('Explained variance ratio')
plt.xlabel('Principal components')

plt.show()

pca = PCA(n_components=6)
X_train_pca = pca.fit_transform(X_train_std)
X_test_pca = pca.transform(X_test_std)
X_test_pca_ans = pca.transform(X_ans_test_std)

"""Plotando"""

plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1])
plt.xlabel('PC 1')
plt.ylabel('PC 2')
plt.show()

"""Randon Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV




param_grid = {  'n_estimators': [1, 2, 4, 6, 8, 10, 25, 50, 100],
                'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
                'criterion': ['entropy']}

rfc = RandomForestClassifier()
gs_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, verbose=False, cv=5, n_jobs=-1, return_train_score=True, scoring='accuracy')
gs_rfc.fit(X_train_pca, y_train)
#y_test_RF =gs_rfc.predict(X_test_)

print(gs_rfc.best_params_)
print(gs_rfc.best_score_)

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics


clf = DecisionTreeClassifier(criterion="entropy", max_depth=4)
X_combined = np.vstack((X_train_pca, X_test_pca))
y_combined = np.hstack((y_train, y_test))


clf = DecisionTreeClassifier()
clf = clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

print("Accuracy Decision Three:",metrics.accuracy_score(y_test, y_pred))

"""Treino usando perceptron"""

from sklearn.linear_model import Perceptron
from sklearn.metrics import accuracy_score

ppn = Perceptron(max_iter=1000, eta0=0.1, random_state=1)
ppn.fit(X_train_std, y_train)
y_pred = ppn.predict(X_test_std)
print('Misclassified samples: %d' % (y_test != y_pred).sum())
print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))

"""Extraindo o melhor resuldado para CSV"""

#melhor resuldado foi do Randon Forest
y_test_RF =gs_rfc.predict(X_test_pca_ans)
answ = {'PassengerId': test[:,0], 'Survived': y_test_RF}
answ = pd.DataFrame.from_dict(answ)
compression_opts = dict(method='zip', archive_name='out.csv')  
answ.to_csv('out.zip', index=False, compression=compression_opts)  
!cp out.zip "/content/drive/MyDrive/Colab Notebooks/"

"""Pipeline => logistic regression"""

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline

pipe_lr = make_pipeline(StandardScaler(),PCA(n_components=4), LogisticRegression(random_state=1))

pipe_lr.fit(X_train, y_train)
y_pred_p = pipe_lr.predict(X_test)
print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))
