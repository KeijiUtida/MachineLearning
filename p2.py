# -*- coding: utf-8 -*-
"""Pratica2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16XHPsl-fvQZxRQ7ZuYs2givNYeo0Sd6Y
"""

from os import listdir
from google.colab import drive
drive.mount('/content/drive')

"""Carregando nomes dos arquivos csv"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import glob                                                                                     
import statistics

path = '/content/drive/MyDrive/Colab Notebooks'

#files adl
csv_files_ADL = glob.glob(os.path.join(path+"/ADL/Train/", "*.csv"))
#files fall
csv_files_Fall = glob.glob(os.path.join(path+"/Fall/Train/", "*.csv"))
#files adl test
csv_files_TestADL = glob.glob(os.path.join(path+"/ADL/Test/", "*.csv"))
#files fall test
csv_files_TestFall = glob.glob(os.path.join(path+"/Fall/Test/", "*.csv"))

csv_files_Fall

"""Extraindo dados do csv"""

def extractingData(data):
  auxData = list()
  for f in data:
    df = pd.read_csv(f , index_col=None, header=None, names=['Time','Sv','Ac1','Ac2','Ac3'])
    auxData.append(df)
  return auxData

dataSetFall = extractingData(csv_files_Fall)
dataSetADL = extractingData(csv_files_ADL)
dataSetTestADL = extractingData(csv_files_TestADL)
dataSetTestFall = extractingData(csv_files_TestFall)

"""Dataset => Modificando o dataset para valores estatísticos"""

#Aqui foi feito o dataset com a soma dos valores estatisticos
def createDataset (data, FallValue):
    auxValues1 = list()
    auxValues2 = list()
    auxValues3 = list()
    for f in data:
        Column0 = f.iloc[: , 0].values
        Column1 = f.iloc[: , 1].values
        Column2 = f.iloc[: , 2].values
        Column3 = f.iloc[: , 3].values
        auxValues1.append([statistics.mean(Column1),max(Column1),statistics.stdev(Column1),min(Column1), FallValue])
        auxValues2.append([statistics.mean(Column2),max(Column2),statistics.stdev(Column2),min(Column2),  0])
        auxValues3.append([statistics.mean(Column3),max(Column3),statistics.stdev(Column3),min(Column3),  0])


    npAuxValues1 = np.array(auxValues1) 
    npAuxValues2 = np.array(auxValues2) 
    npAuxValues3 = np.array(auxValues3) 
    return  npAuxValues1 + npAuxValues2 #+ npAuxValues3 => Aqui por testes obtive o melhor resultado sem os valores estatisticos da quarta coluna




sumstatisticsADL = createDataset(data = dataSetADL, FallValue = 0)
sumstatisticsFall = createDataset(dataSetFall, FallValue = 1)
sumstatisticsADLTest = createDataset(dataSetTestADL, FallValue = 0)
sumstatisticsFallTest = createDataset(dataSetTestFall, FallValue = 1)


totalDataset = np.append(sumstatisticsADL ,sumstatisticsFall,axis=0 )
totalTestDataset = np.append(sumstatisticsADLTest, sumstatisticsFallTest,axis=0)


#fig1, ax1    = plt.subplots()
#ax1.plot(sumstatisticsADL[:,0], sumstatisticsADL[:,2])

"""Visualização dos dados"""

def plot_data(df_list, target_column, title, y_lim):
  fig, axs = plt.subplots(1, 5, figsize=(30,5))
  fig.suptitle(title, fontsize=16)
  for index in range(5):
    axs[index].plot(df_list[index]['Time'], df_list[index][target_column])
    axs[index].set_xlabel('Time', fontsize=14)
    axs[index].set_ylabel(target_column, fontsize=14)
    axs[index].set_ylim(y_lim)

plot_data(dataSetADL, 'Ac1', 'ADL', (-4, 4))
plot_data(dataSetFall, 'Ac1', 'Fall', (-4, 4))

"""Visualizacao => Dados do segundoacelerometro"""

plot_data(dataSetADL, 'Ac2', 'ADL', (-4, 4))
plot_data(dataSetFall, 'Ac2', 'Fall', (-4, 4))

"""Visualizacao => Dados do segundoacelerometro"""

plot_data(dataSetADL, 'Ac3', 'ADL', (-4, 4))
plot_data(dataSetFall, 'Ac3', 'Fall', (-4, 4))

"""Treino => Decision tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics


clf = DecisionTreeClassifier(criterion="entropy", max_depth=4)

X_train = totalDataset[:,[1,2,3]]
X_test = totalTestDataset[:,[1,2,3]]
y_train = totalDataset[:,4]
y_test = totalTestDataset[:,4]


X_combined = np.vstack((X_train, X_test))
y_combined = np.hstack((y_train, y_test))


clf = DecisionTreeClassifier()
clf = clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

"""Treino usando Randon Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

model = RandomForestClassifier(**gs_rfc.best_params_)


param_grid = {  'n_estimators': [1, 2, 4, 6, 8, 10, 25, 50, 100],
                'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
                'criterion': ['entropy']}

rfc = RandomForestClassifier()
gs_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, verbose=False, cv=5, n_jobs=-1, return_train_score=True, scoring='accuracy')
gs_rfc.fit(X_train, y_train)

print(gs_rfc.best_params_)
print(gs_rfc.best_score_)